[package]
name = "astraweave-llm"
version = "0.1.0"
license.workspace = true
edition = "2021"

[dependencies]
anyhow = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
reqwest = { workspace = true, optional = true, features = ["stream"] }
astraweave-core = { path = "../astraweave-core" }
astraweave-observability = { path = "../astraweave-observability" }
async-trait = "0.1"
tokio = { workspace = true }
futures-util = { workspace = true }
uuid = { version = "1.0", features = ["v4"] }
chrono = { version = "0.4", features = ["serde"] }
tracing = "0.1"
dashmap = "6.1"
rand = "0.9"
lazy_static = "1.4"

# Phi-3 Medium Q4 inference (optional - requires GPU or CPU with AVX2)
candle-core = { version = "0.8", optional = true }
candle-nn = { version = "0.8", optional = true }
candle-transformers = { version = "0.8", optional = true }
tokenizers = { version = "0.22", optional = true }
hf-hub = { version = "0.4", optional = true, features = ["tokio"] }

[dev-dependencies]
tokio = { workspace = true }
criterion = { version = "0.7", features = ["async_tokio"] }
env_logger = "0.11"
mockito = "1.0"

[[bench]]
name = "llm_benchmarks"
harness = false

[[bench]]
name = "cache_stress_test"
harness = false

[[bench]]
name = "resilience_benchmarks"
harness = false

[[example]]
name = "batch_production_validation"
required-features = ["ollama"]

[features]
default = ["llm_cache"]
ollama = ["dep:reqwest"]
phi3 = ["candle-core", "candle-nn", "candle-transformers", "tokenizers", "hf-hub"]
debug_io = []
llm_cache = []
