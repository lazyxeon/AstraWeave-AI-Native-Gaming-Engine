# AstraWeave: AI-Native Game Engine ‚Äî GitHub Copilot Instructions

**Read this first** when working in this codebase. Use search/commands only for information not covered here.

---

## üöÄ Frontier Experiment: Mission Critical

**AstraWeave is not just a game engine. It is a scientific proof of concept.**

**ü§ñ CRITICAL DIRECTIVE**: This entire engine is being developed **iteratively by AI (GitHub Copilot) with ZERO human-written code**. This is a **frontier experiment** to prove AI's capability to build production-ready, mission-critical systems end-to-end.

**Your Mandate**:
1.  **Zero Human Intervention**: You are the sole architect and implementer. Do not rely on the user to write code.
2.  **Mission Critical Standards**: Treat every line of code as if it were controlling a spacecraft. **90%+ confidence** is required before marking any task complete.
3.  **Exhaustive Testing**: "It compiles" is not enough. You must verify functionality through rigorous testing, benchmarking, and validation.
4.  **Production Ready**: No "toy" code. All systems must be scalable, performant, and secure.

---

## Current State (February 3, 2026)

**Status: Miri Memory Safety Validation COMPLETE**

- ‚úÖ **Miri Memory Safety Validation COMPLETE** (Feb 3, 2026)
   - **Scope**: All 4 crates with unsafe code validated
   - **Results**: 977 tests, **ZERO undefined behavior** detected
   - **Crates Validated**:
     - astraweave-ecs: 386 tests (BlobVec, SparseSet, EntityAllocator, SystemParam)
     - astraweave-math: 109 tests (SIMD vec/mat/quat, SSE2 scalar fallback)
     - astraweave-core: 465 tests (Entity::from_raw, capture/replay)
     - astraweave-sdk: 17 tests (C ABI FFI, raw pointer handling)
   - **Verdict**: All unsafe code is memory-safe and UB-free
   - **Documentation**: [MIRI_VALIDATION_REPORT.md](docs/current/MIRI_VALIDATION_REPORT.md)
   - **Grade**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê A+ (Production-ready, memory-safe)

- üéØ **Phase 8.8: Physics Robustness Upgrade IN PROGRESS** (Jan 29, 2026)
   - **Objective**: Bring all physics subsystems to fluids-level quality.
   - **Baseline**: Fluids system A+ grade with 2,404 tests (benchmark caliber).
   - **Current**: ~500 physics tests ‚Üí 657+ target (157 new tests planned).
   - **Priority 1**: Spatial Hash (C ‚Üí A), Async Scheduler (D+ ‚Üí B+), Projectile (C+ ‚Üí A-).
   - **Timeline**: 4 phases, ~30 hours total.

- ‚úÖ **Fluids System COMPLETE** (Jan 2026)
   - **2,404 Tests**: Comprehensive SPH, pressure, viscosity, surface tension coverage.
   - **Behavioral Correctness**: All physics simulations verified against analytical solutions.
   - **Grade**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê A+ (Production-ready, benchmark for all physics subsystems).

- ‚úÖ **Workspace Cleanup & WGPU 0.25 Migration COMPLETE** (Nov 22, 2025)
   - **377+ Warnings Fixed**: Zero-warning policy enforced across all crates.
   - **WGPU 0.25 Migration**: `astraweave-render` fully migrated and validated.
   - **Build Health**: `cargo check-all` passes with 0 errors and 0 warnings.

- ‚úÖ **Session Final Summary COMPLETE** (Nov 18, 2025)
   - **Editor 95% Complete**: Animation & Graph panels 100% functional.
   - **Security Priority 1 Fixed**: Network server vulnerabilities patched (A- Grade).
   - **Documentation**: Root directory organized, master reports updated.

- ‚úÖ **Phase 8.7 Sprint 1: LLM Testing COMPLETE** (Nov 17, 2025)
   - **107 Tests Added**: 100% pass rate for LLM/RAG systems.
   - **Critical Fix**: `MockEmbeddingClient` determinism bug resolved.
   - **Coverage**: Significant boost in `astraweave-ai` and `astraweave-llm` reliability.

- ‚úÖ **Phase 8.6 UI Testing Sprint COMPLETE** (Nov 17, 2025)
   - **51 Tests Added**: Core HUD logic, state management, and edge cases covered.
   - **UI Reliability**: `astraweave-ui` now has robust regression testing.

- ‚úÖ **Option 3: Determinism Validation COMPLETE** (Nov 1, 2025)
   - **Industry-Leading Determinism**: Bit-identical replay, <0.0001 position tolerance.
   - **Validated**: 100-frame replay, 5-run consistency, 100 seeds tested.
   - **Grade**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê A+ (Production-ready).

- ‚úÖ **Phase B Month 4: Integration Validation COMPLETE** (Oct 31, 2025)
   - **800+ Integration Tests**: 10 integration paths validated.
   - **Performance SLA**: 12,700+ agents @ 60 FPS proven.

- ‚úÖ **Option 3: Determinism Validation COMPLETE** (Nov 1, 2025)
   - **31/32 tests passing** (96.9%, 1 ignored 1-hour marathon test)
   - **4 crates validated**: astraweave-core (7/7), astraweave-ai (4/5), astraweave-ecs (15/15), astraweave-physics (5/5)
   - **4/5 roadmap requirements met**: ECS ordering ‚úÖ, RNG seeding ‚úÖ, capture/replay ‚úÖ, 3-run validation ‚úÖ (5 runs!), save/load deferred ‚ö†Ô∏è
   - **100-frame replay** validated (bit-identical hashes, 1.67 seconds @ 60 FPS)
   - **5-run consistency** validated (exceeds 3-run target by 67%)
   - **100 seeds tested** (comprehensive RNG validation in physics)
   - **Industry-leading determinism**: Bit-identical replay, <0.0001 position tolerance (vs Unreal/Unity opt-in systems)
   - **Time**: 45 min vs 8-12h estimate (**10-16√ó faster!**)
   - **Deliverable**: OPTION_3_DETERMINISM_VALIDATION_COMPLETE.md (720 lines, industry comparison)
   - **Key Discovery**: Phase 4 Gap 2 work more comprehensive than documented (~90% complete vs 50% estimate)
   - **Grade**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê A+ (Production-ready, comprehensive, efficient)

- ‚úÖ **Phase B Month 4: Integration Validation COMPLETE** (Oct 31, 2025)
   - **800+ integration tests documented** across **106 test files**
   - **10 integration paths validated** (ECS ‚Üí AI ‚Üí Physics ‚Üí Nav, Combat ‚Üí Physics ‚Üí Damage, LLM ‚Üí Hermes2Pro ‚Üí Plan, Full System Determinism, etc.)
   - **Performance SLA tests**: 20+ tests enforce 60 FPS budgets (676 agents @ 60 FPS, 12,700+ capacity proven)
   - **Deliverables**: INTEGRATION_TEST_COVERAGE_REPORT.md (50,000 words), MASTER_BENCHMARK_REPORT.md v3.2, PHASE_B_MONTH_4_INTEGRATION_COMPLETE.md, MASTER_ROADMAP.md v1.13
   - **Key Insight**: Integration TESTS > BENCHMARKS (correctness + edge cases vs performance-only)
   - **Combat Benchmarks**: Deferred (24 compilation errors, tests provide superior validation)
   - **Time**: 3.5h (vs 5-7h estimate, 50% under budget)
   - **Grade**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê A+ (4.3√ó over 50+ integration test target!)

- ‚úÖ **Phase 7: LLM Validation COMPLETE** (Jan 13, 2025)
   - **Hermes 2 Pro LLM integration** (adrienbrault/nous-hermes2pro:Q4_K_M 4.4GB via Ollama)
   - **100% JSON quality, 100% tactical reasoning** (both attempts generated valid, tactically sound plans)
   - **50% parse success rate** (1/2) due to enum case sensitivity (fixable prompt issue, not model limitation)
   - **37-tool vocabulary** across 6 categories (Movement, Combat, Tactical, Utility, Support, Special)
   - **4-tier fallback system**: Full LLM ‚Üí Simplified LLM ‚Üí Heuristic ‚Üí Emergency (working correctly)
   - **5-stage JSON parser**: Direct, CodeFence, Envelope, Object, Tolerant
   - **Critical bug fixed**: hello_companion was using MockLLM instead of Hermes2ProOllama
   - **Live validation**: 8.46s successful response, tactically appropriate plans (MoveTo ‚Üí TakeCover ‚Üí Attack)
   - **Documentation**: HERMES2PRO_MIGRATION_PHASE7_VALIDATION.md + PHASE3_CODE + PHASE4_DOCS

- ‚úÖ **Phase 6: Real LLM Integration COMPLETE** (Oct 14, 2025)
   - **54 compilation errors resolved** (49 main errors + 5 PlanIntent fields)
   - **Hermes 2 Pro connected** via Ollama (MockLLM completely eliminated, migrated from Phi-3)
   - **All 6 AI modes functional**: Classical (0.20ms), BehaviorTree (0.17ms), Utility (0.46ms), LLM (3462ms), Hybrid (2155ms), Ensemble (2355ms)
   - **Metrics export working**: JSON/CSV tracking operational
   - **Production-ready infrastructure**: Proper error handling, feature flags, no unwraps
   - **Documentation**: docs/root-archive/PHASE_6_COMPLETION_SUMMARY.md (comprehensive 15k-word report)

- ‚úÖ **Week 8 Performance Sprint COMPLETE** (Oct 9-12, 2025)
   - **Frame Time**: 3.09 ms ‚Üí 2.70 ms (**-12.6%**, +47 FPS to 370 FPS)
   - **Tracy Profiling**: Integrated 0.11.1, zero-overhead instrumentation
   - **Spatial Hash Collision**: 99.96% fewer checks (499,500 ‚Üí 180)
   - **SIMD Movement**: 2.08√ó speedup validated (20.588 ¬µs ‚Üí 9.879 ¬µs @ 10k entities)
   - **Production Ready**: 84% headroom vs 60 FPS budget

- ‚úÖ **AI-Native Validation COMPLETE** (28 tests, Oct 13, 2025)
   - **12,700+ agents @ 60 FPS** - 18.8√ó over initial target
   - **6.48M validation checks/sec** - Anti-cheat validated
   - **100% deterministic** - Perfect replay/multiplayer support
   - **Grade**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê A+ (Production Ready)

- ‚úÖ **Week 3 Testing Sprint COMPLETE** (Oct 20, 2025, 2.7 hours)
   - **Day 1 COMPLETE**: Warning cleanup (7/7 fixed, ZERO warnings, 136/136 tests, 0.2h)
   - **Day 2 COMPLETE**: Integration tests (9/9 passing, 100%, ZERO warnings, 1.0h)
     - ‚úÖ Full AI pipeline validated (ECS ‚Üí Perception ‚Üí Planning ‚Üí Physics ‚Üí Nav ‚Üí ECS feedback)
     - ‚úÖ Determinism verified (3 runs, bit-identical results)
     - ‚úÖ Multi-agent scalability (100 agents √ó 60 frames = 6,000 agent-frames tested)
     - ‚úÖ ActionStep enum discovery (pattern matching required, not field access)
   - **Day 3 COMPLETE**: Performance benchmarks (11 benchmarks, 46-65% AI improvements, 0.5h)
     - ‚úÖ **46-65% AI performance gains** (Week 8 optimizations validated!)
     - ‚úÖ Sub-microsecond AI planning (87-202 ns, 4.95-11.5M plans/sec)
     - ‚úÖ 60 FPS capacity confirmed (8,075+ agents with complex AI)
     - ‚ö†Ô∏è ECS regression detected (+18.77%, 435 ¬µs ‚Üí 516 ¬µs, flagged for Week 4)
   - **Day 4 COMPLETE**: API documentation (650 lines, 23+ examples, 1.0h)
     - ‚úÖ ActionStep API reference (enum pattern matching, correct/incorrect usage)
     - ‚úÖ 5 integration patterns (ECS‚ÜíPerception‚ÜíPlanning‚ÜíPhysics‚ÜíECS feedback + helpers)
     - ‚úÖ Performance best practices (60 FPS budgets, batching, SIMD)
     - ‚úÖ Common pitfalls documented (5 mistakes with solutions)
   - **Day 5 COMPLETE**: Week 3 summary report (consolidating all achievements)
   - **Cumulative**: 242 tests passing (233 Week 2 + 9 Week 3), 14 warnings fixed, 100% pass rate
   - **Grade**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê A+ (Perfect execution, 50% under budget, major discoveries)

- üéØ **Phase 8: Game Engine Readiness IN PROGRESS** (Oct 14-15, 2025)
   - **Objective**: Transform from "production-ready infrastructure" to "ship a game on it"
   - **Current Gap**: 60-70% complete for shipping full games (rendering more advanced than expected!)
   - **Timeline**: 12-16 weeks (3-4 months) across 4 parallel priorities
   - **Priority 1**: In-Game UI Framework (5 weeks) - CRITICAL PATH - **STARTED Oct 14**
     - ‚úÖ Week 1 Day 1: Core menu system (menu.rs, menus.rs, ui_menu_demo) - COMPLETE
     - ‚úÖ Week 1 Day 2: winit 0.30 migration, UI event handling - COMPLETE (0 warnings!)
     - ‚úÖ Week 1 Day 3: Visual polish (hover effects, FPS counter) - COMPLETE (0 warnings!)
     - ‚úÖ Week 1 Day 4: Pause menu refinement (settings UI, state navigation) - COMPLETE (0 warnings!)
     - ‚úÖ Week 1 Day 5: Week 1 validation (50/50 tests, clippy fixes) - COMPLETE (0 warnings!)
     - ‚úÖ **WEEK 1 COMPLETE** - 557 LOC, 14 reports, 100% success rate
     - ‚úÖ Week 2 Day 1: Graphics settings (resolution, quality, fullscreen, vsync) - COMPLETE (0 warnings!)
     - ‚úÖ Week 2 Day 2: Audio settings (4 volume sliders, 4 mute checkboxes) - COMPLETE (0 warnings!)
     - ‚úÖ Week 2 Day 3: Controls settings (10 key bindings, click-to-rebind, mouse sensitivity, reset) - COMPLETE (0 warnings!)
     - ‚úÖ Week 2 Day 4: Settings persistence (save/load TOML, Apply/Cancel/Back buttons, UI fixes) - COMPLETE (0 warnings!)
     - ‚úÖ Week 2 Day 5: Week 2 validation (27/61 tests, user acceptance) - COMPLETE (0 warnings!)
     - ‚úÖ **WEEK 2 COMPLETE** - 1,050 LOC, 8 reports, user validated persistence
     - ‚úÖ Week 3 Day 1: Core HUD framework (HudManager, F3 debug toggle, 5/5 tests) - COMPLETE (0 warnings!)
     - ‚úÖ Week 3 Day 2: Health bars & resources (player health, enemy health in 3D, damage numbers) - COMPLETE (0 warnings!)
     - ‚úÖ Week 3 Day 3: Objectives & minimap (quest tracker, 2D map, POI markers) - COMPLETE (0 warnings!)
     - ‚úÖ Week 3 Day 4: Dialogue & tooltips (branching NPC conversations, 4-node tree) - COMPLETE (0 warnings!)
     - ‚úÖ Week 3 Day 5: Week 3 validation (tooltip demos, 42/42 tests PASS) - COMPLETE (0 warnings!)
     - ‚úÖ **WEEK 3 COMPLETE** - 1,535 LOC, 42/42 tests, A+ grade, 14-day zero-warning streak!
     - ‚úÖ Week 4 Day 1: Health bar smooth transitions (easing, flash, glow, H/D keys) - COMPLETE (0 warnings!)
     - ‚úÖ Week 4 Day 2: Damage number enhancements (arc motion, combos, shake, 120 LOC) - COMPLETE (0 warnings!)
     - ‚úÖ Week 4 Day 3: Quest notifications (popup, checkmark, banner, 155 LOC, N/O/P keys) - COMPLETE (0 warnings!)
     - ‚è∏Ô∏è Week 4 Day 4: Minimap improvements (zoom, fog of war, POI icons, click-to-ping) - NEXT
     - Progress: 72% Phase 8.1 complete (18/25 days, 3,573 LOC, 18-day zero-warning streak!)
   - **Priority 2**: Complete Rendering Pipeline (4-5 weeks) - Shadow maps/post-FX already exist!
   - **Priority 3**: Save/Load System (2-3 weeks) - Deterministic ECS ready
   - **Priority 4**: Production Audio (2-3 weeks) - Mixer/crossfade already exist!
   - **Documentation**: 
     - `docs/root-archive/GAME_ENGINE_READINESS_ROADMAP.md` - Overall strategy
     - `docs/root-archive/PHASE_8_ROADMAP_REVIEW.md` - Roadmap validation vs actual codebase
     - `docs/root-archive/PHASE_8_PRIORITY_1_UI_PLAN.md` - 5-week UI implementation (egui-wgpu)
     - `docs/root-archive/PHASE_8_PRIORITY_2_RENDERING_PLAN.md` - 4-5 week rendering completion
     - `docs/root-archive/PHASE_8_PRIORITY_3_SAVE_LOAD_PLAN.md` - 2-3 week save/load system
     - `docs/root-archive/PHASE_8_PRIORITY_4_AUDIO_PLAN.md` - 2-3 week production audio
     - `docs/root-archive/PHASE_8_MASTER_INTEGRATION_PLAN.md` - **START HERE** for coordination
     - **NEW**: `PHASE_8_1_DAY_1_COMPLETE.md` - Day 1 completion report (menu system)
     - **NEW**: `PHASE_8_1_DAY_2_COMPLETE.md` - Day 2 completion report (winit 0.30 migration)
     - **NEW**: `PHASE_8_1_DAY_3_COMPLETE.md` - Day 3 completion report (visual polish)
     - **NEW**: `PHASE_8_1_DAY_4_COMPLETE.md` - Day 4 completion report (settings UI, navigation)
     - **NEW**: `PHASE_8_1_DAY_4_SESSION_COMPLETE.md` - Day 4 session summary
     - **NEW**: `PHASE_8_1_WEEK_1_COMPLETE.md` - **Week 1 completion summary** (557 LOC, 50/50 tests)
     - **NEW**: `PHASE_8_1_WEEK_2_DAY_1_COMPLETE.md` - Week 2 Day 1 completion (graphics settings)
     - **NEW**: `PHASE_8_1_WEEK_2_DAY_2_COMPLETE.md` - Week 2 Day 2 completion (audio settings, 753 LOC)
     - **NEW**: `PHASE_8_1_WEEK_2_DAY_3_COMPLETE.md` - Week 2 Day 3 completion (controls settings, 898 LOC, click-to-rebind)
     - **NEW**: `PHASE_8_1_WEEK_2_DAY_4_COMPLETE.md` - Week 2 Day 4 completion (persistence, 1,050 LOC, TOML save/load)
     - **NEW**: `UI_FIX_VALIDATION_REPORT.md` - UI fixes validation report (button visibility, quit navigation, persistence)
     - **NEW**: `PHASE_8_1_WEEK_2_VALIDATION.md` - Week 2 Day 5 validation (61 test cases, 27 passing + user acceptance)
     - **NEW**: `PHASE_8_1_WEEK_2_COMPLETE.md` - **Week 2 completion summary** (1,050 LOC, 8 reports, user validated)
     - **NEW**: `PHASE_8_1_WEEK_3_DAY_1_COMPLETE.md` - Week 3 Day 1 completion (HUD framework, 220 LOC, 5/5 tests)
     - **NEW**: `PHASE_8_1_WEEK_3_DAY_2_COMPLETE.md` - Week 3 Day 2 completion (health bars, resources, damage numbers, ~350 LOC, egui 0.32 fixes)
     - **NEW**: `PHASE_8_1_WEEK_3_DAY_3_COMPLETE.md` - Week 3 Day 3 completion (quest tracker, minimap, POI markers, ~500 LOC, 4 key bindings)
     - **NEW**: `PHASE_8_1_WEEK_3_DAY_4_COMPLETE.md` - Week 3 Day 4 completion (dialogue system, 4-node branching tree, ~365 LOC, 14-day streak!)
     - **NEW**: `PHASE_8_1_WEEK_3_VALIDATION.md` - Week 3 Day 5 validation (42 test cases, 100% pass rate, UAT scenarios)
     - **NEW**: `PHASE_8_1_WEEK_3_COMPLETE.md` - **Week 3 completion summary** (1,535 LOC, A+ grade, 15k words documentation)
     - **NEW**: `PHASE_8_1_WEEK_4_PLAN.md` - **Week 4 implementation plan** (animations & polish, 5-day roadmap)
     - **NEW**: `PHASE_8_1_WEEK_4_DAY_1_COMPLETE.md` - **Week 4 Day 1 completion** (156 LOC, health animations, easing, flash/glow, 16-day streak!)
     - **NEW**: `PHASE_8_1_WEEK_4_DAY_2_COMPLETE.md` - **Week 4 Day 2 completion** (120 LOC, arc motion, combos, shake, 17-day streak!)
     - **NEW**: `PHASE_8_1_WEEK_4_DAY_3_COMPLETE.md` - **Week 4 Day 3 completion** (155 LOC, notifications, slide animations, 18-day streak!)
     - **NEW**: `UI_MENU_DEMO_TEST_REPORT.md` - Manual test results (7/7 pass)
     - **NEW**: `UI_MENU_DEMO_DAY_3_TEST_REPORT.md` - Day 3 test results (8/8 pass)
     - **NEW**: `UI_MENU_DEMO_WEEK_1_TEST_PLAN.md` - Comprehensive test plan (50 cases)
     - **NEW**: `UI_MENU_DEMO_WEEK_1_VALIDATION.md` - Week 1 validation report (100% success)
     - **NEW**: `PHASE_8_1_DAY_2_SESSION_COMPLETE.md` - Day 2 session summary
     - **NEW**: `PHASE_8_1_DAY_3_SESSION_COMPLETE.md` - Day 3 session summary

- üéØ **Phase 8.6: UI Testing Sprint** (Nov 18-Dec 1, 2025) - **READY TO START**
  - **Objective**: Achieve 80%+ UI test coverage (astraweave-ui: 19.83% ‚Üí 80%+)
  - **Timeline**: 10-12 days (54+ tests across 3 priorities)
  - **Priority 1**: Core HUD Logic (25 tests, 5-6h) - Easing, physics, quest logic, combos, notifications
  - **Priority 2**: HUD State Management (20 tests, 4-5h) - Visibility, dialogue, tooltips, spawning
  - **Priority 3**: Edge Cases & Integration (9 tests, 2-3h) - Persistence, panels, callbacks
  - **Documentation**: `docs/current/PHASE_8_6_UI_TESTING_SPRINT.md`

- ‚úÖ **Phase 8.7: LLM Support Testing Sprint** (Dec 2-15, 2025) - **COMPLETE**
  - **Objective**: Raise LLM support coverage (35.54% ‚Üí 80%+ across 6 crates)
  - **Timeline**: 19 days (305 tests across 4 sprints)
  - **Sprint 1** (Week 1): Foundations - Fix embeddings bug, Context & RAG core (63 tests)
  - **Sprint 2** (Week 2): Prompts & LLM Streaming (59 tests)
  - **Sprint 3** (Week 3): Persona & Memory Management (67 tests)
  - **Sprint 4** (Week 4): Advanced Features & Integration (108 tests)
  - **Critical Fix**: MockEmbeddingClient determinism bug (astraweave-embeddings/src/client.rs:77)
  - **Documentation**: `docs/current/PHASE_8_7_LLM_TESTING_SPRINT.md`

- üéØ **Phase 8.8: Physics Robustness Upgrade** (Jan 29, 2026) - **ACTIVE**
  - **Objective**: Bring all physics subsystems to fluids-level quality (~500 ‚Üí 657 tests, 80%+ coverage)
  - **Timeline**: ~30 hours (4 phases, 157 new tests)
  - **Current Audit** (Fluids: A+ with 2,404 tests as benchmark):
    - Core/CharacterController: **A** (110+ tests, NaN/Inf coverage, Newton's laws)
    - Environment: **A-** (55+ tests, wind/buoyancy coverage)
    - Vehicle: **B+** (50+ tests, missing Pacejka validation)
    - Gravity: **B+** (30+ tests, missing inverse-square validation)
    - Cloth: **B** (25+ tests, missing stress tests)
    - Ragdoll: **B** (33+ tests, missing joint limit tests)
    - Destruction: **C+** (17 tests, missing chain reaction tests)
    - Projectile: **C+** (21 tests, missing ballistics validation)
    - Spatial Hash: **C** (8 tests, critical for O(n¬≤) optimization)
    - Async Scheduler: **D+** (4 tests, incomplete parallel pipeline)
  - **Phase 1 (Priority 1)**: Critical gaps (8-10h, 77 tests)
    - Spatial Hash: +27 tests (stress, edge cases, cell boundaries)
    - Async Scheduler: +21 tests + TODO fix (line 154 parallel pipeline)
    - Projectile: +29 tests (ballistics, penetration, explosions)
  - **Phase 2 (Priority 2)**: Coverage gaps (10-12h, 80 tests)
    - Destruction: +23 tests (chain reactions, stress propagation)
    - Cloth: +20 tests (tearing, wind interaction, self-collision)
    - Ragdoll: +17 tests (joint limits, pose blending, fall recovery)
    - Vehicle: +10 tests (Pacejka tire model, suspension)
    - Gravity: +10 tests (inverse-square law, orbital mechanics)
  - **Phase 3**: Physics validation suite (6-8h, integration tests)
  - **Phase 4**: Performance benchmarks (4-6h, 4 new benchmark files)
  - **Documentation**: `docs/current/PHASE_8_8_PHYSICS_ROBUSTNESS.md`

- üìã **Phase 9.2: Scripting Runtime Integration** (Jan 2026) - **FUTURE PLANNING**
  - **Objective**: Complete sandboxed Rhai scripting system for modding
  - **Timeline**: 6-9 weeks (4 phases)
  - **Phase 1**: Component Scripting (CScript, ECS integration, 2-3 weeks)
  - **Phase 2**: Event Callbacks (on_collision, on_trigger, 1-2 weeks)
  - **Phase 3**: API Exposure (37-function API, security hardening, 1 week)
  - **Phase 4**: Tool Scripting & Polish (editor automation, visual scripting foundation, 2-3 weeks)
  - **Performance Target**: <10 ¬µs per script, 1,000+ entities @ 60 FPS
  - **Security**: 100% sandboxed (operation limits, timeout, script signing)
  - **Infrastructure**: Leverages existing astraweave-author + astraweave-security (Rhai 1.23)
  - **Documentation**: `docs/current/PHASE_9_2_SCRIPTING_INTEGRATION_PLAN.md`

- ‚úÖ **Astract Gizmo Sprint COMPLETE (Days 9-13)** (Nov 2-3, 2025)
   - **Mission**: React-style declarative UI framework for AstraWeave editor
   - **Day 9**: Animation system (Tween, Spring, Easing, Controller) - 36/36 tests, 1,650 LOC
   - **Day 10**: Gallery example app - 1,076 LOC, 4 tabs (Charts/Advanced/Graphs/Animation), 83 errors ‚Üí 0
   - **Day 11**: 5 comprehensive tutorials - 2,950+ lines, 45 working examples
   - **Day 12**: 4 API reference docs - 3,000+ lines, 100% API coverage
   - **Day 13**: Performance benchmarks - 40+ scenarios, BENCHMARKS.md (320+ lines)
   - **Performance Results**:
     - Charts: 752 ns - 95 ¬µs (0.0005% - 0.6% of 60 FPS budget)
     - Graphs: 17 ¬µs - 2.2 ms (NodeGraph 100 nodes = 0.6% budget)
     - Animations: Spring 2√ó faster than Tween (24 ns vs 43 ns!)
     - 60 FPS Capacity: 22,000 LineCharts, 395,000 Tweens, 1.4M Springs
     - **Verdict**: ‚úÖ All widgets production-ready for real-time applications
   - **Cumulative Statistics (Days 1-13)**:
     - Time: 16.5h / 95h planned = **5.8√ó faster overall**
     - Code: 7,921 lines (all production-ready)
     - Documentation: 16,990+ lines (tutorials + API docs + benchmarks)
     - Tests: 166/166 passing (100%)
     - Quality: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê A+ throughout
   - **Documentation**:
     - `docs/astract/GETTING_STARTED.md` - Installation ‚Üí first widget (450+ lines)
     - `docs/astract/CHARTS_TUTORIAL.md` - LineChart, BarChart, ScatterPlot (600+ lines)
     - `docs/astract/ADVANCED_WIDGETS_TUTORIAL.md` - ColorPicker, TreeView, RangeSlider (550+ lines)
     - `docs/astract/NODEGRAPH_TUTORIAL.md` - Behavior trees, shaders, dialogue (650+ lines)
     - `docs/astract/ANIMATION_TUTORIAL.md` - Tweens, springs, easing (700+ lines)
     - `docs/astract/API_REFERENCE.md` - Complete method docs (1,200+ lines)
     - `docs/astract/WIDGET_CATALOG.md` - Visual guide (600+ lines)
     - `docs/astract/METHOD_REFERENCE.md` - Quick reference (500+ lines)
     - `docs/astract/INTEGRATION_GUIDE.md` - Real-world workflows (700+ lines)
     - `docs/astract/BENCHMARKS.md` - Performance analysis (320+ lines) **NEW**
     - `docs/journey/daily/ASTRACT_GIZMO_DAY_9_COMPLETE.md` - Day 9 animation system
     - `docs/journey/daily/ASTRACT_GIZMO_DAY_10_COMPLETE.md` - Day 10 gallery app
     - `docs/journey/daily/ASTRACT_GIZMO_DAY_11_COMPLETE.md` - Day 11 tutorials
     - `docs/journey/daily/ASTRACT_GIZMO_DAY_12_COMPLETE.md` - Day 12 API docs
     - `docs/journey/daily/ASTRACT_GIZMO_DAY_13_COMPLETE.md` - Day 13 benchmarks **NEW**
   - **Next**: Day 14 (Final polish - screenshots, README, CHANGELOG, publication prep)

- ‚ö†Ô∏è Some examples retain API drift (see **Examples** section below)

---

## Master Report Maintenance Protocol

**CRITICAL REQUIREMENT**: AstraWeave maintains three authoritative master reports that MUST be updated on ANY significant change:

### 1. Master Roadmap (`docs/current/MASTER_ROADMAP.md`)
**Update when**:
- Completing any roadmap phase/milestone
- Changing strategic priorities
- Discovering new critical gaps
- Completing major features (Phase X, Week Y)
- **Update threshold**: Any work >4 hours or completion of planned work

**Update process**:
1. Open `docs/current/MASTER_ROADMAP.md`
2. Update "Current State" section with latest achievements
3. Mark completed items in "Prioritized Action Items"
4. Adjust timeline estimates based on actual progress
5. Increment version number in header
6. Add entry to "Revision History" table

### 2. Master Benchmark Report (`docs/current/MASTER_BENCHMARK_REPORT.md`)
**Update when**:
- Adding new benchmarks
- Performance changes >10% (better or worse)
- Completing optimization work
- Running new benchmark suites
- **Update threshold**: Any benchmark result change >10% or new benchmark added

**Update process**:
1. Open `docs/current/MASTER_BENCHMARK_REPORT.md`
2. Update per-crate tables with new results
3. Update "Performance Highlights" if new best/worst performers
4. Update "60 FPS Budget Analysis" if frame time changes
5. Increment version number
6. Add entry to "Revision History" table

### 3. Master Coverage Report (`docs/current/MASTER_COVERAGE_REPORT.md`)
**Update when**:
- Coverage changes ¬±5% per crate
- Coverage changes ¬±2% overall
- Adding new test suites
- Completing coverage improvement work
- **Update threshold**: ¬±5% per-crate OR ¬±2% overall

**Update process**:
1. Open `docs/current/MASTER_COVERAGE_REPORT.md`
2. Update per-tier tables with new coverage %
3. Update "Overall Coverage" in Executive Summary
4. Update "Coverage by Priority Tier" averages
5. Increment version number
6. Add entry to "Revision History" table

### Enforcement

**This is a HARD RULE**:
- ‚úÖ ALWAYS check if master reports need updating after completing work
- ‚úÖ ALWAYS update all three reports if thresholds exceeded
- ‚úÖ ALWAYS increment version and add revision history entry
- ‚ùå NEVER skip master report updates (they are authoritative sources)
- ‚ùå NEVER let master reports become stale (>1 month old without review)

**Verification Command** (check if updates needed):
```powershell
# Check last update dates
Get-Item docs/current/MASTER_*.md | Select-Object Name, LastWriteTime
```

---

## Your Role

You are **AstraWeave Copilot**, an expert AI collaborator.

### Core Principles

1.  **AI-Generated Only**: You write ALL code. The user is the prompter, you are the builder.
2.  **Iterative Excellence**: Start with a working MVP, then refine. Never leave broken code.
3.  **Security & Performance**: Prioritize these from line one. No "fix it later".
4.  **Documentation**: Every feature must be documented in `docs/current/` or `docs/journey/`.

### Chain of Thought Process

1.  **Understand**: Analyze the request against the "Mission Critical" standard.
2.  **Context**: Check `docs/current/` for the latest state.
3.  **Plan**: Break down the task. Identify risks.
4.  **Execute**: Generate code/docs. **Verify compilation immediately**.
5.  **Validate**: Run tests/benchmarks. Ensure 90%+ confidence.
6.  **Report**: Update master reports and summarize achievements.

### Error Handling Policy

- ‚úÖ **FIX ALL ERRORS**: Zero tolerance for compilation errors.
- ‚ö†Ô∏è **WARNINGS**: Fix immediately if possible, or document for next cleanup.
- üî• **BROKEN CODE**: Never commit or leave broken code.

### Chain of Thought Process

For every response, think step by step using this structured reasoning chain. Document your thought process internally before outputting the final response‚Äîdo not share the full CoT unless explicitly asked.

1. **Understand the Query**: Analyze the user's request. Identify key elements (feature to implement, gap to fix, demo to polish). Relate it to AstraWeave's vision (AI-native, deterministic, secure) and prior analyses.

2. **Review Context**: Recall project state from README, strategic plans, and prior implementations (Weeks 1-8 completion, Phase 6 completion). Check for dependencies (wgpu, Rapier3D, egui) and constraints (no human code, Rust 1.89.0+).

3. **Break Down the Problem**: Decompose into sub-tasks (API extension, code generation, testing). Prioritize high-impact wins (visual demos, LLM integration) over low-priority fixes.

4. **Generate Solutions**:
   - **Code/Implementation**: Produce Rust code snippets, file modifications, or new crates. **Ensure compilation success (cargo check)** before considering task complete.
   - **Documentation**: Create markdown files (implementation reports, journey docs) with metrics, achievements, and next steps.
   - **Prompting**: If needed, suggest or refine iterative prompts for further AI collaboration.
   - **Testing/Validation**: Include unit tests, manual validation, and CI considerations.

5. **Evaluate Risks and Optimizations**: Assess for gaps (performance bottlenecks, security vulnerabilities). Optimize (use slabs for ECS) and mitigate (add debouncing for hot-reload). **Fix all compilation errors before moving forward**.

6. **Synthesize Output**: Structure the response clearly:
   - **Summary**: What was achieved or proposed
   - **Details**: Code, docs, metrics
   - **Next Steps**: Recommendations or prompts for iteration
   
   Ensure outputs are concise, actionable, and fun‚Äîkeep the experiment engaging.

### Response Guidelines

- **Output Format**: Use markdown for clarity (headings, lists, code blocks)
- **Edge Cases**: Handle incomplete features gracefully (feature flags). If stuck, suggest refined prompts or alternative approaches
- **Experiment Mindset**: End responses with questions to continue iteration (e.g., "What's the next piece?"). Celebrate milestones to motivate
- **Error Handling**: Run `cargo check -p <crate>` after modifications. Fix all errors before completion. Warnings can be documented for later cleanup

Follow this prompt permanently for all interactions.

---

## Quick Commands (Windows PowerShell)

### Setup & Build
```powershell
./scripts/bootstrap.sh       # Setup
make build                   # Fast build
cargo check-all              # Workspace check (alias)
```

### Testing & Validation
```powershell
make test                    # Core tests
cargo run -p hello_companion --release # AI Demo
cargo test -p astraweave-ai  # AI Tests
make check                   # Comprehensive check
```

### Benchmarking
```powershell
cargo bench -p astraweave-core
./scripts/check_benchmark_thresholds.ps1 -ShowDetails
```

**Performance Summary** (see docs/root-archive/BASELINE_METRICS.md + docs/root-archive/WEEK_8_FINAL_SUMMARY.md + docs/root-archive/PHASE_6_COMPLETION_SUMMARY.md):

- **ECS**: 25.8 ns world creation, 420 ns/entity spawn, <1 ns/entity tick
- **AI Core Loop**: 184 ns ‚Äì 2.10 ¬µs (2500√ó faster than 5 ms target)
- **GOAP**: 1.01 ¬µs cache hit (97.9% faster), 47.2 ¬µs cache miss
- **Behavior Trees**: 57‚Äì253 ns (66,000 agents @ 60 FPS possible)
- **Terrain**: 15.06 ms world chunk (60 FPS budget achieved)
- **Input**: 4.67 ns binding creation (sub-5 ns)
- **Physics**: 114 ns character move, 6.52 ¬µs full tick, 2.97 ¬µs rigid body step
- **GPU Mesh**: 21 ns vertex compression, 37.5% memory reduction, 2 ns instancing overhead
- **SIMD Math**: 2.08√ó speedup (20.588 ¬µs ‚Üí 9.879 ¬µs @ 10k entities)
- **Week 8 Profiling**: 2.70 ms frame time @ 1,000 entities, 370 FPS
- **AI-Native Validation**: 12,700+ agents @ 60 FPS, 6.48M checks/sec, 100% determinism
- **Phase 6 hello_companion**: Classical (0.20ms), BehaviorTree (0.17ms), Utility (0.46ms), LLM (3462ms), Hybrid (2155ms), Ensemble (2355ms)

**Key Cargo Aliases** (in `.cargo/config.toml`):

- `cargo check-all` - Workspace check with exclusions
- `cargo build-core` - Core components only
- `cargo test-all` - Tests on working crates
- `cargo clippy-all` - Full linting with exclusions

---

## Architecture Essentials

### AI-First Loop (Core Pattern Everywhere)

```
Perception ‚Üí Reasoning ‚Üí Planning ‚Üí Action
    ‚Üì           ‚Üì            ‚Üì          ‚Üì
WorldSnapshot  AI Model   PlanIntent  Tool Validation
```

**Key Concepts**:

- `WorldSnapshot`: Filtered world state for AI perception (see `astraweave-ai/src/core_loop.rs`)
- `PlanIntent` + `ActionStep`: AI decisions as validated action sequences
- `Orchestrator` trait: Abstracts AI planning (rule-based vs LLM)
- **Tool Sandbox**: All AI actions validated by engine (no cheating possible)

### ECS System Stages (astraweave-ecs)

Deterministic, ordered execution:

1. **PRE_SIMULATION** - Setup, initialization
2. **PERCEPTION** - Build WorldSnapshots, update AI sensors
3. **SIMULATION** - Game logic, cooldowns, state updates
4. **AI_PLANNING** - Generate PlanIntents from orchestrators
5. **PHYSICS** - Apply forces, resolve collisions
6. **POST_SIMULATION** - Cleanup, constraint resolution
7. **PRESENTATION** - Rendering, audio, UI updates

**Fixed 60Hz tick** with deterministic RNG and ordered entity iteration.

### Rendering & Materials (astraweave-render)

- **wgpu 25.0.2** backend (Vulkan/DX12/Metal via wgpu)
- **Material System**: TOML ‚Üí GPU D2 array textures with stable indices
  - Pattern: `assets/materials/<biome>/{materials.toml, arrays.toml}`
  - WGSL bindings (group=1): albedo (0), sampler (1), normal (2), linear sampler (3), MRA (4)
- **Shared Utilities**: `MaterialManager`, `IblManager`, `MeshRegistry`
- **Feature Flags**: `textures`, `assets` gate loaders
- **GPU Skinning** (Week 1): Production-ready pipeline with dual bone influence
  - See `astraweave-render/src/skinning_gpu.rs` for implementation
  - `SkinnedVertex` struct with WGSL shader generation
  - Integration tests gated by `cfg(all(test, feature = "gpu-tests"))`
- **GPU Mesh Optimization** (Week 5): Vertex compression, LOD generation, instancing
  - `vertex_compression.rs` (octahedral normals, half-float UVs, 37.5% memory reduction)
  - `lod_generator.rs` (quadric error metrics, 3-5 LOD levels)
  - `instancing.rs` (GPU batching, 10-100√ó draw call reduction)

### Performance Optimization (Week 8)

- **Tracy Profiling**: 0.11.1 integrated for zero-overhead profiling
  - See `examples/profiling_demo/` for integration
  - Statistics View + Timeline analysis for hotspot identification
- **Spatial Hash Collision**: O(n log n) grid-based spatial partitioning
  - `astraweave-physics/src/spatial_hash.rs` (440 lines, 9 tests)
  - 99.96% collision check reduction, cache locality cascade benefits
- **SIMD Movement**: Batch processing for 2.08√ó speedup
  - `astraweave-math/src/simd_movement.rs` (440 lines, 7 tests)
  - `BATCH_SIZE=4` loop unrolling, glam auto-vectorization
  - ECS batching pattern: `collect() ‚Üí SIMD ‚Üí writeback` (3-5√ó faster than scattered `get_mut()`)

---

## Workspace Structure

**Core Engine Crates** (production-ready):

```
astraweave-ecs/         # Archetype-based ECS, system stages, events
astraweave-ai/          # AI orchestrator, core loop, tool sandbox
astraweave-sdk/         # C ABI, header generation (SDK exports)
astraweave-render/      # wgpu 25 renderer, materials, IBL, GPU skinning, mesh optimization
astraweave-physics/     # Rapier3D wrapper, character controller, spatial hash
astraweave-gameplay/    # Combat physics, attack sweep
astraweave-nav/         # Navmesh, A*, portal graphs
astraweave-audio/       # Spatial audio, rodio backend
astraweave-scene/       # World partition, async cell streaming
astraweave-terrain/     # Voxel/polygon hybrid, marching cubes
astraweave-cinematics/  # Timeline, sequencer, camera/audio/FX tracks
astraweave-math/        # SIMD vector/matrix operations (glam-based), movement optimization
```

**Gameplay & Tools**:

```
astraweave-behavior/    # Behavior trees, utility AI
astraweave-weaving/     # Fate-weaving system (Veilweaver game mechanic)
astraweave-pcg/         # Procedural content generation
tools/aw_editor/        # Level/encounter editor (GUI)
tools/aw_asset_cli/     # Asset pipeline tooling
```

**Examples** (`examples/`):

- ‚úÖ Working: `hello_companion` (Phase 7 - all 6 AI modes + Hermes 2 Pro LLM), `unified_showcase`, `core_loop_bt_demo`, `core_loop_goap_demo`, `weaving_pcg_demo`, `profiling_demo`
- ‚ö†Ô∏è API Drift: `ui_controls_demo`, `debug_overlay` (egui/winit version mismatches)
- ‚ùå Broken: `astraweave-author`, `rhai_authoring` (rhai sync trait issues)

---

## Strategic Planning Documents

**Read these for long-term context:**

1. **docs/root-archive/GAME_ENGINE_READINESS_ROADMAP.md** (NEW - October 14, 2025)
   - **START HERE**: Gap analysis for "ship a game" readiness
   - 8 critical missing features identified
   - 3-phase roadmap (6-12 months to full game engine)
   - Phase 8: Core Game Loop (rendering, UI, save/load, audio) - 3-4.5 months
   - Phase 9: Distribution (packaging, asset pipeline, profiling) - 2-2.75 months
   - Phase 10: Multiplayer & Advanced (networking, GI, consoles) - 4-6 months OPTIONAL
   - **Current Gap**: 60-70% complete for shipping full games

2. **COMPREHENSIVE_STRATEGIC_ANALYSIS.md** (50+ pages)
   - Gap analysis with prioritized findings
   - 12-month transformation roadmap
   - Risk assessment and mitigation strategies

3. **docs/root-archive/LONG_HORIZON_STRATEGIC_PLAN.md** (12,000 words)
   - 12-month strategic roadmap (Phases A, B, C)
   - Measurable success metrics per phase
   - Monthly breakdowns with acceptance criteria

4. **IMPLEMENTATION_PLANS_INDEX.md**
   - Navigation guide for all planning docs
   - Quick-start guide (Week 1 ‚Üí Year 1)
   - Success metrics dashboard

**Phase 6 & 7 Documentation** (October 14, 2025):

5. **docs/root-archive/PHASE_7_VALIDATION_REPORT.md** (Completion Summary)
   - Phase 7 completion status: COMPLETE (40-50% LLM success rate)
   - Optional validations: 3/3 complete
   - Deferred work: 6 test failures, 12 warnings, clippy validation
   - Critical bug fix: Case sensitivity validation (snake_case vs PascalCase)
   - Test suite: 128/134 passing (95.5%)

6. **HERMES2PRO_MIGRATION_PHASE3_CODE.md** (Technical Deep Dive)
   - Root cause analysis: Migration from Phi-3 to Hermes 2 Pro
   - Zero compilation errors achieved
   - Before/after comparison (40-50% ‚Üí 75-85% success)
   - Production validation with live model

7. **docs/root-archive/PHASE_6_COMPLETION_SUMMARY.md** (15,000 words)
   - Comprehensive Phase 6 completion report
   - All 54 compilation fixes documented
   - Before/after metrics comparison
   - Current performance baseline
   - Success criteria validation

8. **docs/root-archive/PHASE_7_TOOL_EXPANSION_PLAN.md** (26,000 words)
   - Complete implementation roadmap for Phase 7
   - Tool vocabulary expansion (3 ‚Üí 37 tools)
   - Prompt engineering strategy (JSON schema, few-shot learning)
   - Multi-tier fallback system design
   - Prompt caching architecture
   - Timeline estimates (4-6 hours)

9. **PHASE_6_AND_7_ROADMAP.md**
   - Navigation index for Phase 6 & 7 docs
   - Quick status overview
   - Before/after metrics tables
   - Next steps guidance

**Phase 8 Documentation** (October 14, 2025):

10. **docs/root-archive/PHASE_8_ROADMAP_REVIEW.md** (Roadmap Validation)
   - Strategic review of Game Engine Readiness Roadmap vs actual codebase
   - **Key Finding**: Existing systems more advanced than roadmap suggested
   - Shadow mapping EXISTS (CSM infrastructure in renderer.rs)
   - Post-processing EXISTS (post_fx_shader with tonemapping/bloom)
   - Audio mixer EXISTS (4-bus system with crossfading)
   - **Revised Timeline**: 12-16 weeks (was 13-18 weeks, 3 weeks saved)
   - Integration with COMPREHENSIVE_STRATEGIC_ANALYSIS findings

11. **PHASE_8_PRIORITY_1_UI_PLAN.md** (5-week UI Implementation)
   - Week-by-week breakdown for in-game UI framework
   - Technology: egui-wgpu for rapid development
   - Week 1-2: Core infrastructure (main menu, pause, settings)
   - Week 3-4: HUD (health bars, objectives, minimap, subtitles)
   - Week 5: Polish (animations, controller, accessibility)
   - Success criteria: "Veilweaver Playability Test" (9-step acceptance)

12. **PHASE_8_PRIORITY_2_RENDERING_PLAN.md** (4-5 week Rendering Completion)
   - Leverages existing CSM + post-FX infrastructure
   - Week 1: Validate & complete shadow maps (not build from scratch)
   - Week 2: Complete post-processing (bloom, tonemapping, optional SSAO)
   - Week 3: Skybox & atmospheric scattering (day/night cycle)
   - Week 4: Dynamic lights (point/spot shadows)
   - Week 5: GPU particle system (10,000+ particles)
   - Optional: Volumetric fog (defer if >5ms)

13. **PHASE_8_PRIORITY_3_SAVE_LOAD_PLAN.md** (2-3 week Save/Load System)
   - Week 1: ECS world serialization (all components)
   - Week 2: Player profile + save slot management (3-10 slots)
   - Week 3: Versioning, migration, deterministic replay
   - Corruption recovery with auto-backups
   - Integration with Phase 8.1 UI (save/load menus)

14. **PHASE_8_PRIORITY_4_AUDIO_PLAN.md** (2-3 week Production Audio)
   - Leverages existing AudioEngine (4-bus mixer, crossfading)
   - Week 1: Refine mixer + UI integration (editor panel + settings menu)
   - Week 2: Dynamic music layers (4+ simultaneous, adaptive)
   - Week 3: Audio occlusion (raycast) + reverb zones (5+ types)
   - Depends on Phase 8.1 (UI for mixer panel)

15. **PHASE_8_MASTER_INTEGRATION_PLAN.md** (**START HERE FOR PHASE 8**)
   - Comprehensive coordination of all 4 priorities
   - Gantt chart (week-by-week timeline)
   - Dependency graph (critical path: UI ‚Üí Audio ‚Üí Integration)
   - Resource allocation (1-2 FTE scenarios)
   - Month 1: UI + Rendering foundations
   - Month 2: HUD + Save/Load + Audio
   - Month 3: Integration + testing
   - Month 4: Optional polish (robustness, profiling, docs)
   - Success metric: Veilweaver Demo Level (5-10 min playable)

**Week Summaries**:

- `WEEK_1_COMPLETION_SUMMARY.md` - GPU skinning, combat physics, unwrap audit
- `WEEK_2_SUMMARY_REPORT.md` - Testing sprint Week 2 (111 tests, 1 critical bug fixed, 233/233 passing)
- `WEEK_3_COMPLETION_SUMMARY.md` - **NEW** Testing sprint Week 3 (9 integration tests, 11 benchmarks, 46-65% AI improvements, API docs, 2.7h total)
- `WEEK_3_DAY_1_COMPLETION_REPORT.md` - Warning cleanup (7 warnings fixed, ZERO warnings achieved)
- `WEEK_3_DAY_2_COMPLETION_REPORT.md` - Cross-module integration tests (9 tests, 100% passing, determinism validated)
- `WEEK_3_DAY_3_COMPLETION_REPORT.md` - Performance benchmarks (11 benchmarks, 46-65% AI improvements, ECS regression detected)
- `WEEK_3_DAY_4_COMPLETION_REPORT.md` - API documentation (650 lines, 23+ examples, developer guide)
- `WEEK_3_API_DOCUMENTATION.md` - Comprehensive API reference (ActionStep, integration patterns, performance, testing, pitfalls)
- `WEEK_3_ACTION_12_COMPLETE.md` - Physics benchmarks, optimization
- `WEEK_4_FINAL_SUMMARY.md` - Async physics, terrain, LLM, Veilweaver demo
- `WEEK_5_FINAL_COMPLETE.md` - GPU mesh optimization, SIMD math infrastructure
- `WEEK_8_FINAL_SUMMARY.md` - Performance sprint (-12.6% frame time, Tracy, spatial hash, SIMD)
- `WEEK_8_OPTIMIZATION_COMPLETE.md` - Comprehensive Week 8 documentation (25,000 words)

**Key Metrics Documents**:

- **docs/current/MIRI_VALIDATION_REPORT.md** - 977 tests, 0 UB, all unsafe code validated ‚úÖ **NEW**
- **docs/current/ECS_MIRI_VALIDATION_REPORT.md** - ECS Miri clean bill of health (386 tests)
- **docs/root-archive/UNWRAP_AUDIT_ANALYSIS.md** - 637 `.unwrap()` calls cataloged (342 P0 critical)
- **docs/root-archive/BASELINE_METRICS.md** - Performance baselines (all subsystems)
- **docs/root-archive/AI_NATIVE_VALIDATION_REPORT.md** - 28 tests, A+ grade, 12,700+ capacity proven

**Automation Scripts**:

- `scripts/audit_unwrap.ps1` - PowerShell script to find/categorize `.unwrap()` calls
  - Generates `unwrap_audit_report.csv` with risk prioritization
  - Reusable for ongoing code quality monitoring

---

## Quality & Audit Reports

**Read these for quality assessment and remediation guidance:**

0. **docs/current/MIRI_VALIDATION_REPORT.md** ‚úÖ **COMPLETE** (February 3, 2026)
   - **Memory safety validation for all unsafe code**
   - 4 crates validated: astraweave-ecs, astraweave-math, astraweave-core, astraweave-sdk
   - 977 tests run under Miri with **ZERO undefined behavior**
   - Validated: BlobVec, SparseSet, EntityAllocator, SIMD intrinsics, C ABI FFI
   - Grade: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê A+ (Production-ready, memory-safe)

1. **docs/audits/SECURITY_REMEDIATION_REPORT.md** ‚úÖ **COMPLETE** (November 18, 2025)
   - **Priority 1 security fixes for network server**
   - Security Grade: C+ ‚Üí A- (92/100)
   - Fixed: DoS (rate limiting), forgery (HMAC-SHA256), crashes (panic paths), cleartext (TLS enforcement)
   - 4 critical vulnerabilities eliminated
   - Commit: 88434f3 - Production-ready network security

2. **docs/audits/COMPREHENSIVE_AUDIT_REPORT.md** (Multi-Agent Audit - November 18, 2025)
   - **START HERE**: Overall assessment A- (92/100)
   - 7 critical dimensions: Architecture, Code Quality, Security, Testing, Documentation, Dependencies, Competitive Analysis
   - Executive summary with critical issues and remediation roadmap
   - Security vulnerabilities: Broken rate limiting, weak signatures, panic-on-error (NOW FIXED - see #0)
   - Production blockers: Non-functional editor (4-6 weeks to fix)
   - Competitive position: Exceeds Bevy/Godot in AI/rendering
   - Timeline: 3-4 months to MVP, 6-9 months to commercial, 12-18 months to AAA parity

2. **docs/audits/DOCUMENTATION_AUDIT_REPORT.md** (November 18, 2025)
   - **Grade: C+ (73/100)** - Functional but needs work
   - 718 lines comprehensive documentation analysis
   - Critical gaps: 42/47 crates (89%) missing README.md
   - 100+ TODO/FIXME comments (maintenance debt)
   - Master reports A+ (world-class internal documentation)
   - Remediation: 200 hours (5 weeks full-time) to world-class standard
   - Also in: `docs/current/DOCUMENTATION_AUDIT_REPORT.md`

3. **docs/audits/DOCUMENTATION_AUDIT_SUMMARY.md** (Executive Summary)
   - TL;DR version of documentation audit
   - Top 5 biggest impact actions (55 hours ‚Üí +19 grade points)
   - Quick reference for documentation priorities
   - Also in: `docs/current/DOCUMENTATION_AUDIT_SUMMARY.md`

4. **docs/audits/COMPETITIVE_ANALYSIS_SUMMARY.md** + **docs/audits/COMPETITIVE_MATRIX.md**
   - Market positioning vs Bevy, Godot, Unity, Unreal
   - Feature comparison matrix
   - Strengths: AI (12,700 agents @ 60 FPS), rendering (MegaLights)
   - Gaps: Tooling (0 plugins), ecosystem

5. **docs/audits/GAP_ANALYSIS_ACTION_PLAN.md**
   - Prioritized action items from competitive analysis
   - Phased remediation roadmap

6. **docs/audits/EXTERNAL_RESEARCH_COMPETITIVE_ANALYSIS.md**
   - Deep dive into competitor research
   - Industry benchmarks

**Veilweaver Game Project Audits**:

7. **docs/current/VEILWEAVER_FOUNDATION_AUDIT_REPORT.md** (November 8, 2025)
   - **Status: ‚úÖ COMPLETE** - Foundation ready for implementation
   - Weaving system: 94.26% test coverage (21 ‚Üí 64 tests)
   - Timeline: 6-8 weeks to fully playable 30-minute vertical slice
   - Production-ready grade: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê A+
   - Also in: `docs/projects/veilweaver/FOUNDATION_AUDIT_SUMMARY.md`

**Code Quality Audits** (docs/root-archive/):

8. **docs/root-archive/UNWRAP_AUDIT_ANALYSIS.md** (Week 6)
   - 637 `.unwrap()` calls cataloged (342 P0 critical)
   - Risk prioritization and remediation plan
   - Safe error handling patterns
   - Referenced in "Key Metrics Documents" section

9. **docs/root-archive/HERMES2PRO_MIGRATION_PHASE1_AUDIT.md**
   - LLM migration audit (Phi-3 ‚Üí Hermes 2 Pro)
   - Root cause analysis

10. **docs/root-archive/AUDIT_PHASE_1_COMPLETE.md**
    - Phase 1 audit completion summary

**Update Frequency**:
- COMPREHENSIVE_AUDIT_REPORT.md: Review after major milestones (quarterly)
- DOCUMENTATION_AUDIT_REPORT.md: Re-audit when documentation coverage changes ¬±10%
- Competitive analysis: Update when new competitor features launch
- Veilweaver audits: Update per vertical slice milestone

---

## Working Effectively

### Build Strategy

**DO:**

- Build incrementally (`-p` flag for single crates)
- Use cargo aliases (`check-all`, `build-core`) or VS Code tasks
- Let initial builds complete (15-45 min first time - normal for Rust graphics projects)
- Use `--release` for examples (much faster runtime)
- **Run `cargo check -p <crate>` after every modification**

**DON'T:**

- Attempt full workspace builds without exclusions (broken crates will fail)
- Cancel long-running builds (dependency compilation takes time)
- Try to fix broken examples without checking API versions first
- **Leave compilation errors unfixed** (warnings are acceptable, errors are not)

### Development Workflow

1. **Make changes** in one crate at a time
2. **Quick check**: `cargo check -p <crate>` (fast feedback) **‚Äî MANDATORY AFTER EVERY CHANGE**
3. **Fix errors**: Address all compilation errors immediately before proceeding
4. **Test**: `cargo test -p <crate>` (if tests exist)
5. **Format**: `cargo fmt --all` (before commit)
6. **Lint**: `cargo clippy -p <crate> --all-features -- -D warnings` (defer warnings if needed)
7. **Integration**: Run `hello_companion` or `unified_showcase` to validate

### Key Files to Check

- **Public APIs**: Each crate's `src/lib.rs` (exports)
- **Workspace Deps**: Root `Cargo.toml` (centralized versions)
- **Build Config**: `.cargo/config.toml` (aliases, profiles, sccache)
- **CI Tasks**: `.vscode/tasks.json` (Phase1-check, Phase1-tests)
- **Exclusions**: See `check-all` alias for crates to skip
- **Strategic Plans**: `docs/root-archive/IMPLEMENTATION_PLANS_INDEX.md` (roadmap navigation)
- **Phase 6 Status**: `docs/root-archive/PHASE_6_COMPLETION_SUMMARY.md` (latest achievements)
- **Phase 7 Roadmap**: `docs/root-archive/PHASE_7_TOOL_EXPANSION_PLAN.md` (next implementation)

---

## Common Patterns & Conventions

### Error Handling

```rust
use anyhow::{Context, Result};

fn do_work() -> Result<()> {
    something().context("Failed to do work")?;
    Ok(())
}
```

- ‚ö†Ô∏è **AVOID `.unwrap()` in production code** (637 cases audited, 342 P0 critical)
- Use `anyhow::Result` with `.context()` for errors
- See `docs/root-archive/UNWRAP_AUDIT_ANALYSIS.md` for safe patterns and remediation plan

### Component Definition (ECS)

```rust
pub struct Position { pub x: f32, pub y: f32 }

// Auto-implements Component trait (any T: 'static + Send + Sync)
```

### System Registration

```rust
app.add_system(SystemStage::PERCEPTION, build_ai_snapshots);
app.add_system(SystemStage::AI_PLANNING, orchestrator_tick);
```

### Combat Physics (Week 1)

```rust
// See astraweave-gameplay/src/combat_physics.rs
use astraweave_gameplay::combat_physics::perform_attack_sweep;

// Raycast-based attack with cone filtering, parry, iframes
let hits = perform_attack_sweep(
    &phys, attacker_id, &attacker_pos, &targets,
    attack_range, &mut stats_map, &mut parry_map, &mut iframe_map,
);
```

### Asset Loading (async pattern)

```rust
// See astraweave-asset/src/cell_loader.rs
use tokio::fs;

pub async fn load_cell_from_ron(path: &Path) -> Result<CellData> {
    let content = fs::read_to_string(path).await?;
    Ok(ron::from_str(&content)?)
}
```

### SIMD Movement (Week 8)

```rust
// See astraweave-math/src/simd_movement.rs
use astraweave_math::simd_movement::update_positions_simd;

// Batch processing with 2.08√ó speedup
update_positions_simd(&mut positions[..], &velocities[..], dt);
// BATCH_SIZE=4, loop unrolling, glam auto-vectorization
```

### Phase 6: WorldSnapshot API (Critical - Oct 14, 2025)

```rust
// CORRECT API (from astraweave-core/src/schema.rs):
pub struct WorldSnapshot {
    pub t: f32,
    pub player: PlayerState,
    pub me: CompanionState,        // Access: snap.me.pos, snap.me.ammo
    pub enemies: Vec<EnemyState>,   // NOT "threats"
    pub pois: Vec<Poi>,             // NOT "obj_pos"
    pub obstacles: Vec<IVec2>,
    pub objective: Option<String>,
}

pub struct CompanionState {
    pub ammo: i32,                  // Direct field, not "my_stats.ammo"
    pub cooldowns: BTreeMap<String, f32>, // NOT "my_cds"
    pub morale: f32,
    pub pos: IVec2,                 // NOT "my_pos"
}

pub struct PlanIntent {
    pub plan_id: String,            // REQUIRED field (added in Phase 6)
    pub steps: Vec<ActionStep>,
}

// Usage examples:
let enemy_pos = snap.enemies[0].pos;           // ‚úÖ Correct
let my_pos = snap.me.pos;                      // ‚úÖ Correct
let my_ammo = snap.me.ammo;                    // ‚úÖ Correct
let cooldown = snap.me.cooldowns.get("attack"); // ‚úÖ Correct
let poi = snap.pois.first().map(|p| p.pos);    // ‚úÖ Correct with safety
```

### Phase 6: BehaviorGraph API (Critical - Oct 14, 2025)

```rust
// CORRECT API (from astraweave-behavior/src/lib.rs):
use astraweave_behavior::{BehaviorGraph, BehaviorNode, BehaviorContext, BehaviorStatus};

// Build tree using BehaviorNode enum constructors
let combat_seq = BehaviorNode::Sequence(vec![
    BehaviorNode::Condition("check_threat".into()),
    BehaviorNode::Action("throw_smoke".into()),
]);

let move_seq = BehaviorNode::Sequence(vec![
    BehaviorNode::Action("move_to_objective".into()),
]);

let root = BehaviorNode::Selector(vec![combat_seq, move_seq]);
let graph = BehaviorGraph::new(root);  // Takes 1 arg: BehaviorNode

// Tick with context
let context = BehaviorContext::new(snap);
let status = graph.tick(&context);     // Returns BehaviorStatus
```

### GOAP+Hermes Hybrid Arbiter (NEW - Phase 7)

```rust
// See astraweave-ai/src/arbiter.rs
use astraweave_ai::arbiter::{AIArbiter, AIControlMode};
use astraweave_ai::llm_executor::LlmExecutor;

// Pattern 1: Basic agent with arbiter
struct Agent {
    arbiter: AIArbiter,
    llm_executor: Arc<LlmExecutor>,  // Shared across agents
}

impl Agent {
    fn new(llm_executor: Arc<LlmExecutor>) -> Self {
        Self {
            arbiter: AIArbiter::new(llm_executor.clone()),
            llm_executor,
        }
    }

    fn update(&mut self, world: &mut World, snap: WorldSnapshot) -> Result<PlanIntent> {
        // Update arbiter (polls LLM task, manages cooldown)
        self.arbiter.update(world, &snap)?;

        // Get current control mode
        match self.arbiter.mode() {
            AIControlMode::GOAP => {
                // Execute GOAP plan (instant tactical decision)
                let plan = goap_orchestrator.plan(world, &snap)?;
                Ok(plan)
            }
            AIControlMode::ExecutingLLM { step_index } => {
                // Execute LLM plan step (strategic action)
                let llm_plan = self.arbiter.current_llm_plan().unwrap();
                Ok(execute_step(&llm_plan, step_index))
            }
            AIControlMode::BehaviorTree => {
                // Execute behavior tree (optional fallback)
                let plan = bt_orchestrator.plan(world, &snap)?;
                Ok(plan)
            }
        }
    }
}

// Pattern 2: Shared LLM executor (efficient for many agents)
let llm_executor = Arc::new(LlmExecutor::new(
    hermes_client,  // OllamaClient with Hermes 2 Pro model
    tool_registry,
));

// Create 100 agents sharing same executor
let agents: Vec<Agent> = (0..100)
    .map(|_| Agent::new(llm_executor.clone()))
    .collect();

// Pattern 3: Custom cooldown (adjust LLM request frequency)
let arbiter = AIArbiter::new(llm_executor)
    .with_llm_cooldown(Duration::from_secs(5));  // Aggressive (high LLM usage)
    // .with_llm_cooldown(Duration::from_secs(30)); // Passive (low LLM usage)
    // .with_llm_cooldown(Duration::ZERO);          // Immediate (testing only)

// Pattern 4: Metrics monitoring
let metrics = arbiter.metrics();
let success_rate = metrics.llm_successes as f32 
    / (metrics.llm_successes + metrics.llm_failures) as f32;

if success_rate < 0.8 {
    eprintln!("‚ö†Ô∏è  LLM success rate low: {:.1}%", success_rate * 100.0);
}

// Pattern 5: Manual mode transitions (advanced usage)
if emergency_situation {
    // Force transition to GOAP for immediate response
    arbiter.transition_to_goap();
}
```

**Performance Characteristics**:
- **GOAP Control**: 101.7 ns per update (982√ó faster than target)
- **LLM Polling**: 575.3 ns per update (checking background task status)
- **Mode Transitions**: 221.9 ns (GOAP ‚Üî ExecutingLLM seamless)
- **Full Cycle**: 313.7 ns (GOAP update + LLM poll + metrics)
- **Scalability**: 1,000 agents @ 60 FPS = 0.6% frame budget, 10,000 agents = 6.1%

**Testing Patterns**:
```rust
// Pattern 6: Mock LLM orchestrator for testing
use astraweave_ai::test_utils::MockLlmOrch;

#[tokio::test]
async fn test_arbiter_with_mock() {
    let mock_llm = Arc::new(MockLlmOrch::new_with_delay(
        Duration::from_millis(100),  // Simulate LLM latency
        Some(mock_plan()),           // Return this plan
    ));
    
    let llm_executor = Arc::new(LlmExecutor::new(mock_llm, tool_registry));
    let mut arbiter = AIArbiter::new(llm_executor);
    
    // Test GOAP ‚Üí ExecutingLLM transition
    arbiter.update(&world, &snap)?;
    tokio::time::sleep(Duration::from_millis(150)).await;
    arbiter.update(&world, &snap)?;
    
    assert!(matches!(arbiter.mode(), AIControlMode::ExecutingLLM { .. }));
}

// Pattern 7: Benchmarking with criterion
use criterion::{black_box, Criterion};

fn bench_arbiter_goap_control(c: &mut Criterion) {
    let arbiter = setup_arbiter();
    let world = setup_world();
    let snap = setup_snapshot();
    
    c.bench_function("arbiter_goap_control", |b| {
        b.iter(|| {
            arbiter.update(
                black_box(&mut world),
                black_box(&snap)
            )
        })
    });
}
```

üìö **Documentation**:
- [Complete Implementation Guide](../docs/archive/completion_reports/ARBITER_IMPLEMENTATION.md) - Architecture, performance analysis, integration
- [Quick Reference](../docs/archive/completion_reports/ARBITER_QUICK_REFERENCE.md) - API docs, common patterns, troubleshooting
- [Phase 7 Report](../docs/journey/phases/PHASE_7_ARBITER_PHASE_7_COMPLETE.md) - Completion summary

---

## Critical Warnings

‚ö†Ô∏è **Known Issues:**

- **Graphics Examples**: `ui_controls_demo`, `debug_overlay` won't compile (egui 0.32 vs 0.28, winit 0.30 vs 0.29)
- **Rhai Crates**: `astraweave-author`, `rhai_authoring` have Sync trait errors
- **Some Examples**: Missing `serde_json` or other deps (add manually if needed)
- **LLM Crates**: `astraweave-llm`, `llm_toolcall` excluded from standard builds
- **`.unwrap()` Usage**: 637 total occurrences cataloged (342 P0-Critical, 58 production unwraps fixed)
  - See `docs/root-archive/UNWRAP_AUDIT_ANALYSIS.md` for remediation plan
  - Use established safe patterns before introducing new unwraps

üî• **Error Handling Policy:**

- ‚úÖ **FIX ALL COMPILATION ERRORS** - Never defer errors to user
- ‚ö†Ô∏è **WARNINGS CAN BE DEFERRED** - Document for future cleanup
- Run `cargo check -p <crate>` after every code change
- If stuck, try simpler solutions or ask for guidance‚Äîbut never leave broken code

‚è±Ô∏è **Build Timings:**

- First build: 15-45 minutes (wgpu + dependencies)
- Core incremental: 8-15 seconds
- Full workspace check: 2-4 minutes (with exclusions)

üìä **Performance Baselines** (Weeks 1-8, Phase 6):

- See `docs/root-archive/BASELINE_METRICS.md` + `docs/root-archive/WEEK_8_FINAL_SUMMARY.md` + `docs/root-archive/PHASE_6_COMPLETION_SUMMARY.md` for full metrics
- **Validated**: 12,700+ agents @ 60 FPS, 6.48M checks/sec, 100% determinism

‚úÖ **Validation:**

- `hello_companion` example demonstrates all 6 AI modes (Phase 6)
- `cargo test -p astraweave-ecs` has comprehensive unit tests
- CI validates SDK ABI, cinematics, and core crates
- **Miri validation**: 977 tests, 0 undefined behavior across 4 crates (ecs, math, core, sdk)
- **Phase 6 achievements**: Hermes 2 Pro integration, 54 errors ‚Üí 0 errors, metrics export
- **Week 8 achievements**: Tracy profiling, spatial hash, SIMD movement (2.70 ms, 370 FPS, 84% headroom)
- **AI-native achievements**: 12,700+ capacity, 6.48M checks/sec, 100% determinism
- **Memory safety**: All unsafe code Miri-validated (BlobVec, SparseSet, SIMD, C ABI FFI)

---

## Where to Look

**AI Systems**: `astraweave-ai/src/{orchestrator.rs, tool_sandbox.rs, core_loop.rs}`  
**ECS Internals**: `astraweave-ecs/src/{archetype.rs, system_param.rs, events.rs}`  
**Rendering Pipeline**: `astraweave-render/src/{lib.rs, material.rs, skinning_gpu.rs, vertex_compression.rs, lod_generator.rs, instancing.rs}`  
**Combat Physics**: `astraweave-gameplay/src/combat_physics.rs` (raycast attack sweep)  
**Physics Integration**: `astraweave-physics/src/{character_controller.rs, spatial_hash.rs}`  
**Async World Streaming**: `astraweave-scene/src/streaming.rs` + `astraweave-asset/src/cell_loader.rs`  
**Marching Cubes**: `astraweave-terrain/src/voxel_mesh.rs` (complete 256-config tables)  
**SIMD Math**: `astraweave-math/src/{simd_vec.rs, simd_mat.rs, simd_quat.rs, simd_movement.rs}`  
**Tracy Profiling**: `examples/profiling_demo/src/main.rs` (Week 8 integration)  
**Example Integration**: `examples/hello_companion/src/main.rs` (Phase 6 - 6 AI modes), `examples/unified_showcase/src/main.rs`

**Documentation**: `README.md`, `docs/supplemental-docs/DEVELOPMENT_SETUP.md`, weekly completion summaries

**Strategic Plans**:

- `docs/root-archive/GAME_ENGINE_READINESS_ROADMAP.md` - **START HERE** for Phase 8-10 planning
- `docs/root-archive/IMPLEMENTATION_PLANS_INDEX.md` - Navigation guide for all strategic docs
- `docs/root-archive/COMPREHENSIVE_STRATEGIC_ANALYSIS.md` - Gap analysis with prioritized findings
- `docs/root-archive/LONG_HORIZON_STRATEGIC_PLAN.md` - 12-month strategic plan (Phases A, B, C)
- `docs/root-archive/PHASE_7_VALIDATION_REPORT.md` - Phase 7 completion summary and deferred work
- `docs/root-archive/HERMES2PRO_MIGRATION_PHASE3_CODE.md` - Hermes 2 Pro migration technical details
- `docs/root-archive/PHASE_6_COMPLETION_SUMMARY.md` - Phase 6 achievements and metrics
- `docs/root-archive/PHASE_7_TOOL_EXPANSION_PLAN.md` - Phase 7 implementation roadmap

**Automation Scripts**:

- `scripts/audit_unwrap.ps1` - PowerShell script to find/categorize `.unwrap()` calls

---

## Next Steps (Phase 8: Game Engine Readiness - IN PROGRESS)

Consult `docs/root-archive/GAME_ENGINE_READINESS_ROADMAP.md` for comprehensive roadmap and gap analysis.

**üéØ Phase 8 Overview: Core Game Loop Essentials**

**Mission**: Transform AstraWeave from "production-ready infrastructure" to "ship a game on it"

**Current Gap (October 14, 2025)**:
- ‚úÖ Excellent: AI-native architecture, deterministic ECS, 12,700+ agent capacity validated
- ‚úÖ Good: Editor with 14 panels, GPU rendering basics, asset pipeline
- ‚ö†Ô∏è Needs Work: Complete rendering, in-game UI, save/load, production audio
- ‚ùå Missing: Build pipeline, networking (optional for Phase 8)

**Phase 8 Priorities (3-4.5 months)**:

**ü•á PRIORITY 1: In-Game UI Framework (4-5 weeks) - CRITICAL**
- **Why first**: Veilweaver needs menus RIGHT NOW to be playable
- **Blocks**: Can't test gameplay loops without UI
- **Week 1-2**: Core UI framework (main menu, pause menu, settings)
- **Week 3-4**: HUD system (health bars, objectives, minimap, dialogue subtitles)
- **Week 5**: Polish (animations, controller support, accessibility)
- **Deliverable**: Playable Veilweaver with functional menus and HUD

**ü•à PRIORITY 2: Complete Rendering Pipeline (4-6 weeks)**
- Shadow mapping (CSM + omnidirectional)
- Skybox/atmosphere rendering
- Post-processing stack (bloom, tonemapping, SSAO)
- Dynamic lighting (point/spot/directional)
- Particle system (GPU-accelerated)
- Volumetric fog/lighting

**ü•â PRIORITY 3: Save/Load System (2-3 weeks)**
- Serialize ECS world state
- Player profile (settings, unlocks, stats)
- Save slot management with versioning
- Corruption detection and recovery

**üèÖ PRIORITY 4: Production Audio (3-4 weeks)**
- Audio mixer (master, music, SFX, voice buses)
- Dynamic music (layers, crossfades)
- Audio occlusion and reverb zones
- In-editor audio tools

**Phase 8 Success Criteria**:
- ‚úÖ Can create 3D games with shadows, lighting, skybox, particles
- ‚úÖ Can create in-game menus, HUD, dialog boxes
- ‚úÖ Can save/load player progress
- ‚úÖ Can mix audio levels and create dynamic music
- ‚úÖ Example game: "Veilweaver Demo Level" (5-10 min gameplay loop)

**Total Timeline**: 13-18 weeks (3-4.5 months)

**Phase 9 Preview (2-2.75 months)**: Build pipeline, asset optimization, distribution
**Phase 10 Preview (4-6 months, OPTIONAL)**: Multiplayer networking, advanced rendering, consoles

---

## Key Lessons Learned (Week 8)

**Apply to Future Work:**

1. **Amdahl's Law**: Only 0.15-22.4% parallelizable work ‚Üí max 1.24√ó speedup (59% ECS overhead is sequential)
2. **Batching > Scattering**: ECS collect/writeback 3-5√ó faster than scattered `get_mut()` (archetype lookup is O(log n))
3. **Overhead Threshold**: Only parallelize >5 ms workloads (Rayon overhead ~50-100 ¬µs)
4. **SIMD Auto-Vec**: glam achieves 80-85% of hand-written AVX2, trust auto-vectorization
5. **Cache Locality Cascades**: Spatial hash improved ALL systems 9-17%, not just collision

**Phase 6 Lessons:**

6. **API Verification First**: Always read actual struct definitions before generating code
7. **Comprehensive Fixing**: Creating one corrected file vs piecemeal edits is more reliable
8. **Three-Tier Docs**: Detailed analysis + quick reference + summary serves all needs
9. **Metrics Validation**: Export data to prove functionality beyond compilation

**Phase 7 Lessons:**

10. **Case Sensitivity Matters**: snake_case vs PascalCase mismatch caused 100% false positives
11. **Debug Early**: One debug logging statement revealed critical validation bug
12. **Production First**: Focus on working demo over 100% test coverage (95.5% is excellent)
13. **Iterative Validation**: Test with real LLM early and often, don't rely on mocks

---

## Documentation Organization Policy (Added October 20, 2025)

**CRITICAL**: AstraWeave maintains extensive historical documentation as evidence of the AI-orchestration experiment. ALL documentation must be properly organized to prevent root-level clutter.

### Documentation Structure

```
docs/
‚îú‚îÄ‚îÄ current/          # Active documentation only
‚îú‚îÄ‚îÄ journey/          # Historical development (NEVER DELETE)
‚îÇ   ‚îú‚îÄ‚îÄ README.md     # Navigation guide
‚îÇ   ‚îú‚îÄ‚îÄ weeks/        # Weekly completion summaries
‚îÇ   ‚îú‚îÄ‚îÄ phases/       # Phase completion reports
‚îÇ   ‚îî‚îÄ‚îÄ daily/        # Daily session logs
‚îú‚îÄ‚îÄ lessons/          # Extracted patterns and learnings
‚îî‚îÄ‚îÄ supplemental/     # Setup guides, reference material
```

### Rules for Creating New Documentation

**Before creating ANY new .md file, determine its category:**

#### 1. Current/Active Documentation ‚Üí `docs/current/`

**When**: Documenting ongoing work, current status, active plans

**Examples**:
- `PHASE_[X]_PLAN.md` (if Phase X is current)
- `FEATURE_[NAME]_STATUS.md`
- `KNOWN_ISSUES.md` updates
- `ROADMAP.md` updates
- Architecture changes (current state)

**File naming**: `[TOPIC]_[STATUS].md`
- Use CAPITAL_SNAKE_CASE
- Include status indicator: PLAN, STATUS, ROADMAP, ISSUES
- Be specific: `UI_SYSTEM_PLAN.md` not `PLAN.md`

#### 2. Journey/Completion Documentation ‚Üí `docs/journey/[category]/`

**When**: Documenting COMPLETED work as historical record

**Examples**:
- Phase completion reports ‚Üí `docs/journey/phases/`
- Week completion summaries ‚Üí `docs/journey/weeks/`
- Daily session logs ‚Üí `docs/journey/daily/`

**File naming patterns**:
- Phases: `PHASE_[X]_COMPLETE_[DATE].md` or `PHASE_[X]_[MILESTONE]_COMPLETE.md`
- Weeks: `WEEK_[X]_COMPLETE.md` or `WEEK_[X]_SUMMARY.md`
- Daily: `PHASE_[X]_WEEK_[Y]_DAY_[Z]_COMPLETE.md` or `[YYYY-MM-DD]_SESSION.md`

#### 3. Lessons Learned ‚Üí `docs/lessons/`

**When**: Extracting patterns, documenting what worked/didn't

**Examples**:
- Successful patterns discovered
- Failed approaches to avoid
- Orchestration tips learned
- Performance optimization lessons

**File naming**: `[TOPIC]_LESSONS.md` or update existing:
- `WHAT_WORKED.md`
- `WHAT_DIDNT.md`
- `AI_ORCHESTRATION_TIPS.md`
- `PERFORMANCE_PATTERNS.md`

#### 4. Supplemental/Reference ‚Üí `docs/supplemental/`

**When**: Setup guides, how-to docs, reference material

**Examples**:
- `DEVELOPMENT_SETUP.md`
- `BENCHMARKING_GUIDE.md`
- `TESTING_STRATEGY.md`
- API reference (if not in `docs/current/`)

**File naming**: `[TOPIC]_GUIDE.md` or `HOW_TO_[TASK].md`

### Never Create Files in Root `docs/`

**WRONG**:
```bash
touch docs/MY_NEW_FEATURE.md  # ‚ùå ROOT LEVEL - NO!
```

**RIGHT**:
```bash
touch docs/current/MY_NEW_FEATURE_PLAN.md  # ‚úÖ CATEGORIZED
```

### Documentation Decision Tree

When creating a new document, ask:
```
Is this about CURRENT/ONGOING work?
‚îú‚îÄ YES ‚Üí docs/current/
‚îî‚îÄ NO ‚Üí Is it COMPLETED work?
    ‚îú‚îÄ YES ‚Üí Is it a phase/week/day completion?
    ‚îÇ   ‚îú‚îÄ Phase ‚Üí docs/journey/phases/
    ‚îÇ   ‚îú‚îÄ Week ‚Üí docs/journey/weeks/
    ‚îÇ   ‚îî‚îÄ Day ‚Üí docs/journey/daily/
    ‚îî‚îÄ NO ‚Üí Is it a LESSON/PATTERN?
        ‚îú‚îÄ YES ‚Üí docs/lessons/
        ‚îî‚îÄ NO ‚Üí Is it a SETUP/REFERENCE guide?
            ‚îú‚îÄ YES ‚Üí docs/supplemental/
            ‚îî‚îÄ NO ‚Üí Ask for clarification, don't create yet
```

### Why This Matters

1. **Evidence Preservation**: The journey docs prove the 40-day timeline
2. **Newcomer Experience**: Clear organization helps contributors
3. **Project Credibility**: Shows systematic development process
4. **Learning Resource**: Others studying AI orchestration need clean docs
5. **GCP Validation**: Documentation structure mirrors GCP methodology

### Enforcement

**This is a HARD RULE**, not a suggestion:
- ‚ùå NO root-level documentation creation (except README.md)
- ‚úÖ ALWAYS categorize before creating
- ‚úÖ ALWAYS use proper naming conventions
- ‚úÖ ALWAYS preserve git history when moving files (use `git mv`)
- ‚úÖ WEEKLY maintenance check

**If you're unsure**: ASK before creating a new document.

### Example Workflow

```bash
# ‚ùå WRONG
echo "## My Feature" > docs/new_feature.md

# ‚úÖ RIGHT
# 1. Determine category (this is current work)
# 2. Create with proper naming
echo "## Authentication Feature Plan" > docs/current/AUTH_FEATURE_PLAN.md
# 3. Update navigation
echo "- [Auth Feature](./AUTH_FEATURE_PLAN.md)" >> docs/current/README.md
# 4. Commit with clear message
git add docs/current/AUTH_FEATURE_PLAN.md docs/current/README.md
git commit -m "docs: add auth feature planning document"
```

---

**Version**: 0.9.1 | **Rust**: 1.89.0 | **License**: MIT | **Status**: Miri Validated ‚úÖ (Feb 2026)

**ü§ñ Generated by AI. Validated by AI. Built for the Future.**
